---
layout: page
title: Research
sidebar_link: true
---
<!--
<p class="message">
  Carry on!
</p>
-->
<details open="">
<summary><strong>Unsupervised Deep Learning for Computational Photography and Imaging</strong></summary>
<ul>
<!--1-1-->
<details open="">
<summary><strong><small><font color="#004D86">Self2Self: Self-Supervised Image Denoising</font></small></strong></summary>

<table>
<tbody>
<tr>
 <th>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/teaser_1.gif" alt="" height="130" />
  <a>&nbsp;</a>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/r_im2.png" alt="" height="130" />
  <ul>
  <small>
   <li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20x-cvpr-Self2Self%20With%20Dropout%20Learning%20Self-Supervised%20Denoising%20From%20Single%20Image.pdf">Self2Self with dropout: Learning self-supervised denoising from single image</a></strong>, CVPR, 2020.</li>
  </small>
  </ul>
 </th>
</tr>

</tbody>
</table>
</details>
</ul>
</details>

<!--2-->
<details open="">
<summary><strong>Supervised Learning for Image Recovery</strong></summary>
<ul>
<!--2-1-->
<details>
<summary><strong><small><font color="#004D86">Image Denoising via Sequential Ensemble Learning</font></small></strong></summary>

<table>
<tbody>
<tr>
 <th>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/r_im3.png" alt="" height="130"/>
  <a>&nbsp;</a>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_2_1_2.png" alt="" height="130"/>
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20-tip-Image%20Denoising%20via%20Sequential%20Ensemble%20Learning.pdf">Image denoising via sequential ensemble learning</a></strong>, TIP, 2020.</li>
</small>
</ul>
 </th>
</tr>
</tbody>
</table>
</details>

<!--2-2-->
<details>
<summary><strong><small><font color="#004D86">Non-Blind Image Deblurring via Variational-EM-Based Deep Learning</font></small></strong></summary>

<table>
<tbody>
<tr>
 <th>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/r_im4.png" alt="" height="130" />
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20-cvpr-Variational-EM-based%20Deep%20Learning%20for%20Noise-blind%20Image%20Deblurring.pdf">Variational-EM-based deep learning for noise-blind image deblurring</a></strong>, CVPR, 2020.</li>
</small>
</ul>
 </th>
</tr>
</tbody>
</table>
</details>

<!--2-3-->
<details>
<summary><strong><small><font color="#004D86">Super-Resolving Blurry Text Images via Collaborative Deep Learning</font></small></strong></summary>

<table>
<tbody>
<tr>
 <th>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/r_im5.png" alt="" height="130" />
  <a>&nbsp;</a>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/r_im6.png" alt="" height="130"  />
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20x-tci-Collaborative%20Deep%20Learning%20for%20Super-Resolving%20Blurry%20Text%20Images.pdf">Collaborative deep learning for super-resolving blurry text images </a></strong>, TCI, 2020.</li>
</small>
</ul>
 </th>
</tr>
</tbody>
</table>
</details>

<!--2-4-->
<details>
<summary><strong><small><font color="#004D86">Image Raindrop Removal via Shape Attention</font></small></strong></summary>

<table>
<tbody>
<tr>
 <th>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/r_im7.png" alt="" height="130" />
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/r_im8.png" alt="" height="130" />
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_2_4_3.png" alt="" height="130"/>
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/19-iccv-Deep%20Learning%20for%20Seeing%20Through%20Window%20With%20Raindrops.pdf">Deep learning for seeing through window with raindrops </a></strong>, ICCV, 2019.</li>
</small>
</ul>
 </th>
</tr>
</tbody>
</table>
</details>


<!--7-1-->
<details>
<summary><strong><small><font color="#004DB6">Intellectual Property Protection of Supervised Learning Systems in Image Recovery</font> </small></strong></summary>
<table>
<tbody>
<tr>
 <th>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_6_2_1.png" alt="" height="130"/>
  <a>&nbsp;</a>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_6_2_4.png" alt="" height="130"/>
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20x-tnnls-Watermarking%20Deep%20Neural%20Networks%20in%20Image%20Processing.pdf">Watermarking deep neural networks in image processing </a></strong>, TNNLS, 2020.</li>
</small>
</ul>
</th>
</tr>
</tbody>
</table>
</details>




</ul>
</details>



<!---------------------------------4-------------------------------------------------->
<!---------------------------------4-------------------------------------------------->
<!---------------------------------4-------------------------------------------------->
<details open="">
<summary><strong>Exploiting Patch Recurrence for Image Processing</strong></summary>
<ul>
<!--4-1-->
<details>
<summary><strong><small><font color="#004D86">Data-Driven Multi-Scale Non-local Wavelet Frame Construction and Image Recovery</font> </small></strong></summary>
<table>
<tbody>
<tr>
 <th>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_4_1_1.png" alt="" height="130"/>
  <a>&nbsp;</a>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_4_1_2.png" alt="" height="130"/>
  <a>&nbsp;</a>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_4_1_3.png" alt="" height="130"/>
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/15-josc-Data-driven%20multi-scale%20non-local%20wavelet%20frame%20construction%20and%20image%20recovery.pdf">Data-driven multi-scale non-local wavelet frame construction and image recovery </a></strong>, JoSC, 2015.</li>
</small>
</ul>
 </th>
</tr>
</tbody>
</table>
</details>
<!--4-2-->
<details>
<summary><strong><small><font color="#004D86">Cartoon-Texture Decomposition via Discriminative Patch Recurrence </font></small></strong></summary>
<table>
<tbody>
<tr>
 <th>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_4_2_1.png" alt="" height="130"/>
  <a>&nbsp;</a>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_4_2_2.png" alt="" height="130"/>
<ul>
<small>
<li type="disc"><strong><!--<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20x-siam-Cartoon-Texture%20Image%20Decomposition%20using%20Orientation%20Characteristics%20in%20Patch%20Recurrence.pdf">-->Cartoon-texture image decomposition using orientation characteristics in  patch recurrence<!--</a>--></strong>, SIIMS, 2020.</li>
</small>
</ul>
 </th>
</tr>
</tbody>
</table>
</details>
<!--4-3-->
<details>
<summary><strong><small><font color="#004D86">Removing Ghosting Reflections from Single Image </font></small></strong></summary>
<table>
<tbody>
<tr>
 <th>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_4_3_1.png" alt="" height="130"/>
  <a>&nbsp;&nbsp;</a>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_4_3_2.png" alt="" height="130"/>
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20-tci-Removing%20Reflection%20From%20a%20Single%20Image%20With%20Ghosting%20Effect.pdf">Removing reflection from a single image with ghosting effect</a></strong>, TCI, 2020.</li>
</small>
</ul>
 </th>
</tr>
</tbody>
</table>
</details>
</ul>
</details>

<!---------------------------------3-------------------------------------------------->
<!---------------------------------3-------------------------------------------------->
<!---------------------------------3-------------------------------------------------->
<details open="">
<summary><strong> Sparse Representation for Computer Vision and Image Processing</strong></summary>
<ul>
<!--3-1-->
<details>
<summary><strong><small><font color="#004D86">Sparse Coding for Classification: Improving Discrimination</font></small></strong></summary>
<table>
<tbody>
<tr>
 <th>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_3_1_1.png" alt="" height="130"/>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_3_1_2.png" alt="" height="130"/>
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/19-spl-Supervised%20Sparse%20Coding%20With%20Decision%20Forest.pdf">Supervised sparse coding with decision forest</a></strong>, SPL, 2019.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/16-pr-Supervised%20dictionary%20learning%20with%20multiple%20classifier%20integration.pdf">Supervised dictionary learning with multiple classifier integration</a></strong>, PR, 2016.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/16-cvpr-Equiangular%20Kernel%20Dictionary%20Learning%20with%20Applications%20to%20Dynamic%20Texture%20Analysis.pdf">Equiangular kernel dictionary learning with applications to dynamic texture analysis</a></strong>, CVPR, 2016.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/16-cvpr-Sparse%20Coding%20for%20Classification%20via%20Discrimination%20Ensemble.pdf">Sparse coding for classification via discrimination ensemble</a></strong>, CVPR, 2016</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/14-eccv-A%20Convergent%20Incoherent%20Dictionary%20Learning%20Algorithm%20for%20Sparse%20Coding.pdf">A convergent incoherent dictionary learning algorithm for sparse coding</a></strong>, ECCV, 2014.</li>
</small>
</ul>
 </th>
</tr>
</tbody>
</table>
</details>
<!--3-2-->
<details>
<summary><strong><small><font color="#004D86">Sparse Coding and Dictionary Learning on Tensors </font></small></strong></summary>
<table>
<tbody>
<tr>
 <th>
 <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_3_2_1.png" alt="" height="130"/>
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20x-tmm-Factorized%20Tensor%20Dictionary%20Learning%20for%20Visual%20Tensor%20Data%20Completion.PDF">Factorized tensor dictionary learning for visual tensor data completion </a></strong>, TMM, 2020.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/19-tcyb-Exploiting%20Global%20Low-rank%20Structure%20and%20Local%20Sparsity%20Nature%20for%20Tensor%20Completion.pdf">Exploiting global low-rank structure and local sparsity nature for tensor completion </a></strong>, TCYB, 2019.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/15-iccv-Dynamic%20Texture%20Recognition%20via%20Orthogonal%20Tensor%20Dictionary%20Learning.pdf">Dynamic texture recognition via orthogonal tensor dictionary learning </a></strong>, ICCV, 2015.</li>
</small>
</ul>
 </th>
</tr>
</tbody>
</table>
</details>
<!--3-3-->
<details>
<summary><strong><small><font color="#004D86">Sparse Coding for Texture Analysis</font></small></strong></summary>
<table>
<tbody>
<tr>
 <th>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_3_3_1.png" alt="" height="130"/>
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20-spl-Weakly-Supervised%20Sparse%20Coding%20with%20Geometric%20Prior%20for%20Interactive%20Texture%20Segmentation.pdf">Weakly-supervised sparse coding with geometric prior for interactive texture segmentation </a></strong>, SPL, 2020.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/16-cvpr-Equiangular%20Kernel%20Dictionary%20Learning%20with%20Applications%20to%20Dynamic%20Texture%20Analysis.pdf">Equiangular kernel dictionary learning with applications to dynamic texture analysis</a></strong>, CVPR, 2016.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/15-iccv-Dynamic%20Texture%20Recognition%20via%20Orthogonal%20Tensor%20Dictionary%20Learning.pdf">Dynamic texture recognition via orthogonal tensor dictionary learning </a></strong>, ICCV, 2015.</li>
</small>
</ul>
 </th>
</tr>
</tbody>
</table>
</details>
<!--3-4-->
<details>
<summary><strong><small><font color="#004D86">Sparse Coding for Image Quality Assessment </font></small></strong></summary>
<table>
<tbody>
<tr>
 <th>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_3_4_1.png" alt="" height="130"/>
  <a>&nbsp;</a>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_3_4_2.png" alt="" height="130"/>
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20x-tmm-Image%20Quality%20Assessment%20Using%20Kernel%20Sparse%20Coding.pdf">Image quality assessment using kernel sparse coding</a></strong>, TMM, 2020.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20-nca-Full-reference%20image%20quality%20metric%20for%20blurry%20images%20and%20compressed%20images%20using%20hybrid%20dictionary%20learning.pdf">Full-reference image quality metric for blurry images and compressed images using hybrid dictionary learning </a></strong>, NCA, 2020.</li>
</small>
</ul>
 </th>
</tr>
</tbody>
</table>
</details>
<!--3-5-->
<details>
<summary><strong><small><font color="#004D86">Sparse Coding: Algorithms and Convergence Analysis</font> </small></strong></summary>
<table>
<tbody>
<tr>
 <th>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_3_5_1.png" alt="" height="130"/>
  <a>&nbsp;</a>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_3_5_2.png" alt="" height="130"/>
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/16-tpami-Dictionary%20learning%20for%20sparse%20coding_Algorithms%20and%20convergence%20analysis.pdf">Dictionary learning for sparse coding：Algorithms and convergence analysis </a></strong>, TPAMI, 2016.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/14-cvpr-l0%20norm%20based%20dictionary%20learning%20by%20proximal%20methods%20with%20global%20convergence.pdf">L0 norm-based dictionary learning by proximal methods with global convergence</a></strong>, CVPR, 2014.</li>
</small>
</ul>
 </th>
</tr>
</tbody>
</table>
</details>


</ul>
</details>



<!---------------------------------5-------------------------------------------------->
<!---------------------------------5-------------------------------------------------->
<!---------------------------------5-------------------------------------------------->
<details open="">
<summary><strong>Visual Quality Assessment: From Global Statistics to Local Features</strong></summary>
<ul>
<!--5-1-->
<details>
<summary><strong><small><font color="#004D86">Visual Quality Assessment: Sparse Coding Approach</font></small></strong></summary>
<table>
<tbody>
<tr>
 <th>
 <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_5_1_1.png" alt="" height="130"/>
 <a>&nbsp;</a>
 <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_5_1_2.png" alt="" height="130"/>
 <a>&nbsp;</a>
 <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_5_1_3.png" alt="" height="130"/>
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20-nca-Full-reference%20image%20quality%20metric%20for%20blurry%20images%20and%20compressed%20images%20using%20hybrid%20dictionary%20learning.pdf">Full-reference image quality metric for blurry images and compressed images using hybrid dictionary learning </a></strong>, NCA, 2020.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20x-tmm-Image%20Quality%20Assessment%20Using%20Kernel%20Sparse%20Coding.pdf">Image quality assessment using kernel sparse coding</a></strong>, TMM, 2020.</li>
</small>
</ul>
 </th>
</tr>
</tbody>
</table>
</details>
<!--5-2-->
<details>
<summary><strong><small><font color="#004D86">Spatial-Distribution-Aware Image Quality Assessment </font></small></strong></summary>
<table>
<tbody>
<tr>
 <th>
 <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_5_2_0.png" alt="" height="130"/> 
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/15-tip-Fractal%20Analysis%20for%20Reduced%20Reference%20Image%20Quality%20Assessment.pdf">Fractal analysis for reduced reference image quality assessment </a></strong>, TIP, 2015.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/15-sp-Directional%20regularity%20for%20visual%20quality%20estimation.pdf">Directional regularity for visual quality estimation </a></strong>, SP, 2015.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/14-spic-Reduced%20Reference%20Image%20Quality%20Assessment%20Using%20Regularity%20of%20Phase%20Congruency.pdf">Reduced reference image quality assessment using regularity of phase congruency </a></strong>, SPIC, 2014.</li>
</small>
</ul>
 </th>
</tr>
</tbody>
</table>
</details>
<!--5-3-->
<details>
<summary><strong><small><font color="#004D86">Measurring Local Image Distortions </font></small></strong></summary>
<table>
<tbody>
<tr>
 <th>
 <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_7_1_3.png" alt="" height="130" />
 <a>&nbsp;&nbsp;</a>
 <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_7_1_2.png" alt="" height="130" />
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/17-iccv-Estimating%20Defocus%20Blur%20via%20Rank%20of%20Local%20Patches.pdf">Estimating defocus blur via rank of local patches </a></strong>, ICCV, 2017.</li>
</small>
</ul>
 </th>
</tr>
</tbody>
</table>
</details>
</ul>
</details>



<!---------------------------------6-------------------------------------------------->
<!---------------------------------6-------------------------------------------------->
<!---------------------------------6-------------------------------------------------->
<details open="">
<summary><strong>Invariant Features for Visual Recognition</strong></summary>
<ul>
<!--6-1-->
<details>
<summary><strong><small><font color="#004D86">Lacunarity/Fractal Statistics for Texture Recognition</font> </small></strong></summary>
<table>
<tbody>
<tr>
 <th>
 <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/laun.png" alt="" height="130"/>
 <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/laun1.png" alt="" height="130"/>
 <br>
 <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_6_1_1.png" alt="" height="130" />
 <a>&nbsp;</a>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_6_1_2.png" alt="" height="130" />
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/17-cviu-Spatiotemporal%20lacunarity%20spectrum%20for%20dynamic%20texture%20classification.pdf">Spatiotemporal lacunarity spectrum for dynamic texture classification</a></strong>, CVIU, 2017.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/15-icme-CHARACTERIZING%20DYNAMIC%20TEXTURES%20WITH%20SPACE-TIME%20LACUNARITY%20ANALYSIS.pdf">Characterizing dynamic textures with space-time lacunarity analysis </a></strong>, ICME, 2015.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/14-cvpr-Lacunarity%20Analysis%20on%20Image%20Patterns%20for%20Texture%20Classification.pdf">Lacunarity analysis on image patterns for texture classification </a></strong>, CVPR, 2014.</li>

<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/15-pr-Classifying%20dynamic%20textures%20via%20spatiotemporal%20fractal%20analysis.pdf">Classifying dynamic textures via spatiotemporal fractal analysis </a></strong>, PR, 2015.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/14-ivc-A%20distinct%20and%20compact%20texture%20descriptor.pdf">A distinct and compact texture descriptor </a></strong>, IVC, 2014.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/11-iccv-Dynamic%20Texture%20Classification%20Using%20Dynamic%20Fractal%20Analysis.pdf">Dynamic texture classification using dynamic fractal analysis </a></strong>, ICCV, 2011.</li>
</small>
</ul>
</th>
</tr>
</tbody>
</table>
</details>
<!--6-2-->
<!--
<details>
<summary><strong><small><font color="#004D86">Fractal Spetrum Analysis </font></small></strong></summary>
<table>
<tbody>
<tr>
 <th>
 <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_6_1_1.png" alt="" height="130" />
 <a>&nbsp;</a>
  <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_6_1_2.png" alt="" height="130" />
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/15-pr-Classifying%20dynamic%20textures%20via%20spatiotemporal%20fractal%20analysis.pdf">Classifying dynamic textures via spatiotemporal fractal analysis </a></strong>, PR, 2015.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/14-ivc-A%20distinct%20and%20compact%20texture%20descriptor.pdf">A distinct and compact texture descriptor </a></strong>, IVC, 2014.</li>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/11-iccv-Dynamic%20Texture%20Classification%20Using%20Dynamic%20Fractal%20Analysis.pdf">Dynamic texture classification using dynamic fractal analysis </a></strong>, ICCV, 2011.</li>
</small>
</ul>
</th>
</tr>
</tbody>
</table>
</details>-->

<!--7-2-->
<details>
<summary><strong><small><font color="#004D86">Maximum-Torque Contour Descriptor </font></small></strong></summary>
<table>
<tbody>
<tr>
 <th>
 <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_7_2_1.png" alt="" height="130"/>
 <a>&nbsp;&nbsp;</a>
 <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_7_2_3.png" alt="" height="130"/>
 <a>&nbsp;&nbsp;</a>
 <img src="https://github.com/csyhquan/csyhquan.github.io/raw/master/images/im_7_2_4.png" alt="" height="130"/>
<ul>
<small>
<li type="disc"><strong><a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/12-cvpr-Contour-Based%20Recognition.pdf">Contour-based recognition </a></strong>, CVPR, 2012.</li>
</small>
</ul>
</th>
</tr>
</tbody>
</table>
</details>



</ul>
</details>

<!---------------------------------7-------------------------------------------------->
<!---------------------------------7-------------------------------------------------->
<!---------------------------------7-------------------------------------------------->


















