---
layout: category
title: Publication
---

<details open="">
<summary><span style="font-size: 105%;"><strong><small>Upcoming</small></strong></span></summary>
<small>
<ul style="background-color: #f2f2f2;">
<li><span style="font-size: 95%;"><strong>Image quality assessment using kernel sparse coding</strong>  [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20x-tmm-Image%20Quality%20Assessment%20Using%20Kernel%20Sparse%20Coding.pdf">manuscript</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20x-tmm-Image%20Quality%20Assessment%20Using%20Kernel%20Sparse%20Coding%20(SUPP).pdf">supp</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/code/TMM-kernel/TMM-KSC_IQA-FinalCode.rar"><font color="#F75000">code</font></a>]</span><br />
<span style="font-size: 95%;"> Z. Zhou, J. Li, Y. Quan* and R. Xu, <br />
<em>IEEE Transactions on Multimedia (TMM), </em>xx(x): xxx–xxx. xxx 2020</span></li>
<li><span style="font-size: 95%;"><strong>Cartoon-texture image decomposition using orientation characteristics in patch recurrence</strong><!--[<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20x-siam-Cartoon-Texture%20Image%20Decomposition%20using%20Orientation%20Characteristics%20in%20Patch%20Recurrence.pdf">manuscript</a>]--> </span><br />
<span style="font-size: 95%;"> R. Xu, Y. Xu, Y. Quan* and H. Ji<br />
<em>SIAM Journal on Imaging Sciences (SIIMS), </em>xx(x): xxx–xxx. xxx 2020</span></li>
<li><span style="font-size: 95%;"><strong>Collaborative deep learning for super-resolving blurry text images</strong>  [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20x-tci-Collaborative%20Deep%20Learning%20for%20Super-Resolving%20Blurry%20Text%20Images.pdf">manuscript</a>][<a href="https://github.com/csjietingyang/ImplementationOfOurAcceptedPaper"><font color="#F75000">github</font></a>]</span><br />
<span style="font-size: 95%;">Y. Quan, J. Yang, Y. Chen, Y. Xu and H. Ji, <br />
<em>IEEE Transactions on Computational Imaging (TCI), </em>xx(x): xxx–xxx. xxx 2020</span></li>
<li><span style="font-size: 95%;"><strong>Factorized tensor dictionary learning for visual tensor data completion</strong>  [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20x-tmm-Factorized%20Tensor%20Dictionary%20Learning%20for%20Visual%20Tensor%20Data%20Completion.PDF">manuscript</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/code/tensor_completion.rar"><font color="#F75000">code</font></a>]</span><br />
<span style="font-size: 95%;">R. Xu, Y. Xu and Y. Quan*, <br />
<em>IEEE Transactions on Multimedia (TMM), </em>xx(x): xxx–xxx. xxx 2020</span></li>
<li><span style="font-size: 95%;"><strong>Watermarking deep neural networks in image processing</strong>  [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20x-tnnls-Watermarking%20Deep%20Neural%20Networks%20in%20Image%20Processing.pdf">manuscript</a>]</span><br />
<span style="font-size: 95%;"> Y. Quan, H. Teng, Y. Chen and H. Ji, <br />
<em>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), </em>xx(x): xxx–xxx. xxx 2020</span></li>
</ul>
</small>
</details>


<details open="">
<summary><span style="font-size: 105%;"><strong><small>2019 - 2020</small></strong></span></summary>
<small>
<ul style="background-color: #f2f2f2;">
 
<li><span style="font-size: 95%;"><strong>Removing reflection from a single image with ghosting effect</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20-tci-Removing%20Reflection%20From%20a%20Single%20Image%20With%20Ghosting%20Effect.pdf" download="github3">manuscript</a>]</span><br />
<span style="font-size: 95%;"> Y. Huang, Y. Quan*, Y. Xu, R. Xu and H. Ji,<br />
 <em> IEEE Transactions on Computational Imaging (TCI), </em>6(1): 34-45, Dec 2020</span></li>
 <li><span style="font-size: 95%;"><strong>Weakly-supervised sparse coding with geometric prior for interactive texture segmentation</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20-spl-Weakly-Supervised%20Sparse%20Coding%20with%20Geometric%20Prior%20for%20Interactive%20Texture%20Segmentation.pdf" download="github4">manuscript</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20-spl-Weakly-Supervised%20Sparse%20Coding%20with%20Geometric%20Prior%20for%20Interactive%20Texture%20Segmentation%20(SUPP).pdf" download="sup3">supp</a>][<a href="https://github.com/csyanhuang/texSeg"><font color="#F75000">github</font></a>]</span><br />
<span style="font-size: 95%;"> Y. Quan, H. Teng, T. Liu and Y. Huang,<br />
 <em> IEEE Signal Processing Letters (SPL), </em>27(1): 116-120, Dec 2020</span></li>
 <li><span style="font-size: 95%;"><strong>Image denoising via sequential ensemble learning</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20-tip-Image%20Denoising%20via%20Sequential%20Ensemble%20Learning.pdf" download="github4">manuscript</a>][<a href="https://github.com/cs-rukawa/NLED_Code" download="code9"><font color="#F75000">github</font></a>]</span><br />
<span style="font-size: 95%;"> X. Yang, Y. Xu, Y. Quan* and H. Ji,<br />
 <em> IEEE Transactions on Image Processing (TIP), </em>29(1): 5038-5049, Dec 2020</span></li>
 <li><span style="font-size: 95%;"><strong>Self2Self with dropout: Learning self-supervised denoising from single image</strong>  [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20x-cvpr-Self2Self%20With%20Dropout%20Learning%20Self-Supervised%20Denoising%20From%20Single%20Image.pdf">manuscript</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20x-cvpr-Self2Self%20With%20Dropout%20Learning%20Self-Supervised%20Denoising%20From%20Single%20Image%20(SUPP).pdf">supp</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/code/Self2Self/Self2Self.rar"><font color="#F75000">code</font></a>][<a href="https://github.com/scut-mingqinchen/self2self"><font color="#F75000">github</font></a>]</span><br />
<span style="font-size: 95%;"> Y. Quan, M. Chen, T. Pang and H. Ji,<br />
<em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), </em>Jun 2020</span></li><!--Seattle(virtual），Jun-->
<li><span style="font-size: 95%;"><strong>Variational-EM-based deep learning for noise-blind image deblurring</strong>  [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20-cvpr-Variational-EM-based%20Deep%20Learning%20for%20Noise-blind%20Image%20Deblurring.pdf">manuscript</a>]</span><br />
<span style="font-size: 95%;"> Y. Nan, Y. Quan and H. Ji, <br />
<em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), </em>Jun 2020</span></li><!--Seattle(virtual），Jun-->
 <li><span style="font-size: 95%;"><strong>Full-reference image quality metric for blurry images and compressed images using hybrid dictionary learning</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/20-nca-Full-reference%20image%20quality%20metric%20for%20blurry%20images%20and%20compressed%20images%20using%20hybrid%20dictionary%20learning.pdf" download="github">manuscript</a>] </span><br />
<span style="font-size: 95%;"> Z. Zhou, J. Li, Y. Xu and Y. Quan*,<br />
<em> Neural Computing and Applications (NCA), </em>Jan 2020</span></li>


 <li><span style="font-size: 95%;"><strong>Barzilai-Borwein-based adaptive learning rate for deep learning</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/19-pr-Barzilai%E2%80%93Borwein-based%20adaptive%20learning%20rate%20for%20deep%20learning.pdf" download="github6">manuscript</a>]</span><br />
<span style="font-size: 95%;"> J. Liang, Y. Xu, C. Bao, Y. Quan* and H. Ji,<br />
 <em> Pattern Recognition Letters (PRL), </em>128(1): 197-203, Dec 2019</span></li>
 <li><span style="font-size: 95%;"><strong>Exploiting global low-rank structure and local sparsity nature for tensor completion</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/19-tcyb-Exploiting%20Global%20Low-rank%20Structure%20and%20Local%20Sparsity%20Nature%20for%20Tensor%20Completion.pdf" download="github10">manuscript</a>][<a href="https://github.com/csyongdu/Exploiting-Global-Low-Rank-Structure-and-Local-Sparsity-Nature-for-Tensor-Completion"><font color="#F75000">github</font></a>] </span><br />
<span style="font-size: 95%;"> Y. Du, G. Han, Y. Quan, Z. Yu, H. Wong, C. Chen and J. Zhang,<br />
<em> IEEE Transactions on Cybernetics (TCYB),</em> 49(11): 3898-3910, Nov 2019</span></li>
<li><span style="font-size: 95%;"><strong>Deep learning for seeing through window with raindrops</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/19-iccv-Deep%20Learning%20for%20Seeing%20Through%20Window%20With%20Raindrops.pdf" download="github1">manuscript</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/19-iccv-Deep%20Learning%20for%20Seeing%20Through%20Window%20With%20Raindrops%20(SUPP).pdf" download="sup2">supp</a>][<a href="https://github.com/jackiesdd/raindropAttention"><font color="#F75000">github</font></a>]</span><br />
<span style="font-size: 95%;"> Y. Quan, S. Deng, Y. Chen and H. Ji,<br />
 <em> IEEE International Conference on Computer Vision (ICCV), </em>Oct 2019</span></li><!--Seoul, Oct -->
 <!--
<li><span style="font-size: 95%;"><strong>Exploiting label consistency in structured sparse representation for classification</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/19-nca-Exploiting%20label%20consistency%20in%20structured%20sparse%20representation%20for%20classification.pdf" download="github7">manuscript</a>]</span><br />
<span style="font-size: 95%;"> Y. Huang, Y. Quan*, T. Liu and Y. Xu,<br />
<em> Neural Computing and Applications (NCA), </em>31(10): 6509-6520, Oct 2019</span></li>-->
<li><span style="font-size: 95%;"><strong>Attention with structure regularization for action recognition</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/19-cviu-Attention%20with%20structure%20regularization%20for%20action%20recognition.pdf" download="github8">manuscript</a>]</span><br />
<span style="font-size: 95%;"> Y. Quan, Y. Chen, R. Xu and H. Ji,<br />
<em> Computer Vision and Image Understanding (CVIU), </em>187, Oct 2019</span></li>
<!--
<li><span style="font-size: 95%;"><strong>Deeply exploiting long-term view dependency for 3D shape recognition</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/19-access-Deeply%20Exploiting%20Long-Term%20View%20Dependency%20for%203D%20Shape%20Recognition.pdf" download="github9">manuscript</a>] </span><br />
<span style="font-size: 95%;"> Y. Xu, C. Zheng, R. Xu and Y. Quan*,<br />
<em> IEEE Access (ACCESS), </em>7: 111678-111691, Aug 2019</span></li>-->
 <li><span style="font-size: 95%;"><strong>Supervised sparse coding with decision forest</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/19-spl-Supervised%20Sparse%20Coding%20With%20Decision%20Forest.pdf" download="github5">manuscript</a>][<a href="https://github.com/csyanhuang/SCDF" ><font color="#F75000">github</font></a>] </span><br />
<span style="font-size: 95%;"> Y. Huang, Y. Quan* and T. Liu,<br />
 <em> IEEE Signal Processing Letters (SPL), </em>26(2): 327-331, Feb 2019</span></li>
</ul>
</small>
</details>



<details>
<summary><span style="font-size: 105%;"><strong><small>2017 - 2018</small></strong></span></summary>
<small>
<ul style="background-color: #f2f2f2;">
<!--
<li><span style="font-size: 95%;"><strong>Sparse coding and dictionary learning with class-speciﬁc group sparsity</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/18-nca-Sparse%20coding%20and%20dictionary%20learning%20with%20class-speci%EF%AC%81c%20group%20sparsity.pdf" download="github11">manuscript</a>] </span><br />
<span style="font-size: 95%;"> Y. Sun, Y. Quan and J. Fu,<br />
<em> Neural Computing and Applications (NCA),</em> 30(4): 1265-1275, Aug 2018</span></li>-->


<li><span style="font-size: 95%;"><strong>Image-based action recognition using hint-enhanced deep neural network</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/17-nc-Image-based%20action%20recognition%20using%20hint-enhanced%20deep%20neural%20network.pdf" download="github13">manuscript</a>] </span><br />
<span style="font-size: 95%;"> T. Qi, Y. Xu, Y. Quan, Y. Wang and H. Ling,<br />
<em>Neurocomputing (NC), </em>267: 475-488, Dec 2017</span></li>
<li><span style="font-size: 95%;"><strong>Spatiotemporal lacunarity spectrum for dynamic texture classification</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/17-cviu-Spatiotemporal%20lacunarity%20spectrum%20for%20dynamic%20texture%20classification.pdf" download="github14">manuscript</a>] </span><br />
<span style="font-size: 95%;"> Y. Quan, Y. Sun and Y. Xu,<br />
<em>Computer Vision and Image Understanding (CVIU), </em>165: 85-96, Dec 2017</span></li>
<li><span style="font-size: 95%;"><strong>Estimating defocus blur via rank of local patches</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/17-iccv-Estimating%20Defocus%20Blur%20via%20Rank%20of%20Local%20Patches.pdf" download="github12">manuscript</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/17-iccv-Estimating%20Defocus%20Blur%20via%20Rank%20of%20Local%20Patches%20(SUPP).pdf" download="supp">supp</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/code/17-iccv-Estimating%20Defocus%20Blur%20via%20Rank%20of%20Local%20Patches/Defocus_estimator_v1.0.rar" download="code8"><font color="#F75000">code</font></a>]</span><br />
<span style="font-size: 95%;"> G. Xu, Y. Quan and H. Ji,<br />
<em> IEEE International Conference on Computer Vision (ICCV), </em>Oct 2017</span></li><!--Venice, Oct -->
</ul>
</small>
</details>




<details>
<summary><span style="font-size: 105%;"><strong><small>2015 - 2016</small></strong></span></summary>
<small>
<ul style="background-color: #f2f2f2;">
<li><span style="font-size: 95%;"><strong>Dictionary learning for sparse coding: Algorithms and convergence analysis</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/16-tpami-Dictionary%20learning%20for%20sparse%20coding_Algorithms%20and%20convergence%20analysis.pdf" download="github17">manuscript</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/code/l0dl_int.rar" ><font color="#F75000">code</font></a>] </span><br />
<span style="font-size: 95%;"> C. Bao, H. Ji, Y. Quan and Z. Shen,<br />
<em> IEEE Transactions on Patter Analysis and Machine Intelligence (TPAMI),</em> 38(7): 1356-1369, Jul 2016</span></li>
<li><span style="font-size: 95%;"><strong>Supervised dictionary learning with multiple classifier integration</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/16-pr-Supervised%20dictionary%20learning%20with%20multiple%20classifier%20integration.pdf" download="github18">manuscript</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/code/16-pr-Supervised%20dictionary%20learning%20with%20multiple%20classifier%20integration/MCDLv7_pcode.rar" download="code7"><font color="#F75000">code</font></a>] </span><br />
<span style="font-size: 95%;">Y. Quan, Y. Xu, Y. Sun and Y. Huang,<br />
<em> Pattern Recognition (PR),</em> 55: 247-260, Jul 2016</span></li>
<li><span style="font-size: 95%;"><strong>Equiangular kernel dictionary learning with applications to dynamic texture analysis</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/16-cvpr-Equiangular%20Kernel%20Dictionary%20Learning%20with%20Applications%20to%20Dynamic%20Texture%20Analysis.pdf" download="github15">manuscript</a>]</span><br />
<span style="font-size: 95%;">Y. Quan, C. Bao and H. Ji,<br />
<em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), </em>Jun 2016</span></li><!--Las Vegas, Jun, -->
<li><span style="font-size: 95%;"><strong>Sparse coding for classification via discrimination ensemble</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/16-cvpr-Sparse%20Coding%20for%20Classification%20via%20Discrimination%20Ensemble.pdf" download="github16">manuscript</a>]</span><br />
<span style="font-size: 95%;">Y. Quan, Y. Xu, Y. Sun, Y. Huang and H. Ji,<br />
<em> IEEE Conference on Computer Vision and Pattern Recognition (CVPR), </em>Jun 2016</span></li> <!--Las Vegas, Jun, -->


<li><span style="font-size: 95%;"><strong>Dynamic texture recognition via orthogonal tensor dictionary learning</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/15-iccv-Dynamic%20Texture%20Recognition%20via%20Orthogonal%20Tensor%20Dictionary%20Learning.pdf" download="github20">manuscript</a>]</span><br />
<span style="font-size: 95%;">Y. Quan, Y. Huang and H. Ji,<br />
<em> IEEE International Conference on Computer Vision (ICCV), </em>Dec 2015</span></li><!--Santiago, Dec, -->
<li><span style="font-size: 95%;"><strong>Classifying dynamic textures via spatiotemporal fractal analysis</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/15-pr-Classifying%20dynamic%20textures%20via%20spatiotemporal%20fractal%20analysis.pdf" download="github24">manuscript</a>] </span><br />
<span style="font-size: 95%;">Y. Xu, Y. Quan*, Z. Zhang, H. Ling and H. Ji,<br />
<em> Pattern Recognition (PR),</em> 48(10): 3239-3248, Oct 2015</span></li>
<li><span style="font-size: 95%;"><strong>Structured sparse coding for classification via reweighted l<sub>1,2</sub> minimization</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/15-cccv-Structured%20Sparse%20Coding%20for%20Classification%20via%20Reweighted%20l12%20minimization.pdf" download="github21">manuscript</a>]</span><br />
<span style="font-size: 95%;">Y. Xu, Y. Sun, Y. Quan and Y. Luo,<br />
<em> The Chinese Conference on Computer Vision (CCCV), </em>Sep 2015</span></li><!--Xi'an, Sep, -->
<li><span style="font-size: 95%;"><strong>Fractal analysis for reduced reference image quality assessment</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/15-tip-Fractal%20Analysis%20for%20Reduced%20Reference%20Image%20Quality%20Assessment.pdf" download="github22">manuscript</a>] </span><br />
<span style="font-size: 95%;"> Y. Xu, D. Liu, Y. Quan and P. Callet,<br />
<em> IEEE Transactions on Image Processing (TIP),</em> 24(7): 2089-2109, Jul 2015</span></li>
<li><span style="font-size: 95%;"><strong>Discriminative structured dictionary learning with hierarchical group sparsity</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/15-cviu-Discriminative%20structured%20dictionary%20learning%20with%20hierarchical%20group%20sparsity.pdf" download="github26">manuscript</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/code/15-cviu-Discriminative%20structured%20dictionary%20learning%20with%20hierarchical%20group%20sparsity/child_dl_v2.rar" download="code6"><font color="#F75000">code</font></a>]</span><br />
<span style="font-size: 95%;">Y. Xu, Y. Sun, Y. Quan and B. Zheng,<br />
<em> Computer Vision and Image Understanding (CVIU),</em> 136: 59-68, Jul 2015</span></li>
<li><span style="font-size: 95%;"><strong>Characterizing dynamic textures with space-time lacunarity analysis</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/15-icme-CHARACTERIZING%20DYNAMIC%20TEXTURES%20WITH%20SPACE-TIME%20LACUNARITY%20ANALYSIS.pdf" download="github19">manuscript</a>]</span><br />
<span style="font-size: 95%;">Y. Sun, Y. Xu and Y. Quan,<br />
<em> IEEE International Conference on Multimedia and Expo (ICME), </em>Oral, Jun 2015</span></li><!--Torino, Jun, -->
<li><span style="font-size: 95%;"><strong>Directional regularity for visual quality estimation</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/15-sp-Directional%20regularity%20for%20visual%20quality%20estimation.pdf" download="github23">manuscript</a>] </span><br />
<span style="font-size: 95%;">D. Liu, Y. Xu, Y. Quan, Z. Yu and P. Callet,<br />
<em> Signal Processing (SP),</em> 110: 211-221, May 2015</span></li>
<li><span style="font-size: 95%;"><strong>Data-driven multi-scale non-local wavelet frame construction and image recovery</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/15-josc-Data-driven%20multi-scale%20non-local%20wavelet%20frame%20construction%20and%20image%20recovery.pdf" download="github25">manuscript</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/code/15-josc-Data-driven%20multi-scale%20non-local%20wavelet%20frame%20construction%20and%20image%20recovery/NLFrame.rar" download="code5"><font color="#F75000">code</font></a>] </span><br />
<span style="font-size: 95%;">Y. Quan, H. Ji and Z. Shen,<br />
<em> Journal of Scientific Computing (JoSC),</em> 63(2): 307-329, May 2015</span></li>
</ul>
</small>
</details>





<details>
<summary><span style="font-size: 105%;"><strong><small>2013 - 2014</small></strong></span></summary>
<small>
<ul style="background-color: #f2f2f2;">
<li><span style="font-size: 95%;"><strong>A convergent incoherent dictionary learning algorithm for sparse coding</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/14-eccv-A%20Convergent%20Incoherent%20Dictionary%20Learning%20Algorithm%20for%20Sparse%20Coding.pdf" download="github27">manuscript</a>]</span><br />
<span style="font-size: 95%;">C. Bao, Y. Quan and H. Ji,<br />
<em> European Conference on Computer Vision (ECCV), </em>Sep 2014</span></li><!--Zurich, Sep -->
<li><span style="font-size: 95%;"><strong>Reduced reference image quality assessment using regularity of phase congruency</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/14-spic-Reduced%20Reference%20Image%20Quality%20Assessment%20Using%20Regularity%20of%20Phase%20Congruency.pdf" download="github30">manuscript</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/code/kernel-iqa.rar" ><font color="#F75000">code</font></a>] </span><br />
<span style="font-size: 95%;">D. Liu, Y. Xu, Y. Quan and P. Callet,<br />
<em> Signal Processing: Image Communication (SPIC),</em> 29(8): 844-855, Sep 2014</span></li>
<li><span style="font-size: 95%;"><strong>L<sub>0</sub> norm based dictionary learning by proximal methods with global convergence</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/14-cvpr-l0%20norm%20based%20dictionary%20learning%20by%20proximal%20methods%20with%20global%20convergence.pdf" download="github28">manuscript</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/code/14-cvpr-l0%20norm%20based%20dictionary%20learning%20by%20proximal%20methods%20with%20global%20convergence/l0_dicti_learning_v2.rar" download="code4"><font color="#F75000">code</font></a>]</span><br />
<span style="font-size: 95%;">C. Bao, H. Ji, Y. Quan and Z. Shen,<br />
<em>  IEEE Conference on Computer Vision and Pattern Recognition (CVPR), </em>oral, Jun 2014</span></li><!--Columbus, Jun -->
<li><span style="font-size: 95%;"><strong>Lacunarity analysis on image patterns for texture classification</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/14-cvpr-Lacunarity%20Analysis%20on%20Image%20Patterns%20for%20Texture%20Classification.pdf" download="github29">manuscript</a>]</span><br />
<span style="font-size: 95%;">Y. Quan, Y. Xu, Y. Sun and Y. Luo,<br />
<em>  IEEE Conference on Computer Vision and Pattern Recognition (CVPR), </em>Jun 2014</span></li><!--Columbus, Jun -->
<li><span style="font-size: 95%;"><strong>A distinct and compact texture descriptor</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/14-ivc-A%20distinct%20and%20compact%20texture%20descriptor.pdf" download="github31">manuscript</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/code/14-ivc-A%20distinct%20and%20compact%20texture%20descriptor/pfs_v1.rar" download="code3"><font color="#F75000">code</font></a>]</span><br />
<span style="font-size: 95%;"> Y. Quan, Y. Xu and Y. Sun,<br />
<em> Image and Vision Computing (IVC),</em> 32(4): 250-259, Apr 2014</span></li>
</ul>
</small>
</details>


<details>
<summary><span style="font-size: 105%;"><strong><small>2011 - 2012</small></strong></span></summary>
<small>
<ul style="background-color: #f2f2f2;">
<li><span style="font-size: 95%;"><strong>Contour-based recognition</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/12-cvpr-Contour-Based%20Recognition.pdf" download="github33">manuscript</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/code/12-cvpr-Contour-Based%20Recognition/mtp_demo_v3.rar" download="code2"><font color="#F75000">code</font></a>]</span><br />
<span style="font-size: 95%;">Y. Xu; Y. Quan, Z. Zhang, H. Ji, C. Fermüller, M. Nishigaki and D. Dementhon,<br />
<em>  IEEE Conference on Computer Vision and Pattern Recognition (CVPR), </em>Jun 2012</span></li><!--Rhode Island, Jun -->
<li><span style="font-size: 95%;"><strong>Dynamic texture classification using dynamic fractal analysis</strong> [<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/manuscript/11-iccv-Dynamic%20Texture%20Classification%20Using%20Dynamic%20Fractal%20Analysis.pdf" download="github34">manuscript</a>][<a href="https://github.com/csyhquan/csyhquan.github.io/raw/master/code/11-iccv-Dynamic%20Texture%20Classification%20Using%20Dynamic%20Fractal%20Analysis/dfs_toolbox_v5.rar" download="code1"><font color="#F75000">code</font></a>]</span><br />
<span style="font-size: 95%;">Y. Xu, Y. Quan, H. Ling and H. Ji,<br />
<em>  IEEE International Conference on Computer Vision (ICCV), </em>Nov 2011</span></li><!--Barcelona, Nov -->
</ul>
</small>
</details>